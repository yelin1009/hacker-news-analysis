{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hacker News Data Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this project, we'll work with a dataset of submissions to popular technolofty site Hacker News.\n",
    "\n",
    "We have reduced from almost 300,0000 rows to approximately 20,000 rows by removing all submissions that didn't receive any comments and then randomly sampling from the remaining submissions. \n",
    "\n",
    "Below are descriptions of the columns:\n",
    "\n",
    "    - id: the unique identifier from Hacker News for the post\n",
    "    - title: the title of the post\n",
    "    - url: the URL that the posts links to, if the post has a URL\n",
    "    - num_points: the number of points the post acquired, calculated as the total number of upvotes minus the total number of downvotes\n",
    "    - num_comments: the number of comments on the post\n",
    "    - author: the username of the person who submitted the post\n",
    "    - created at: the date and time of the post's submission\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from csv import reader\n",
    "opened_file = open('hacker_news.csv')\n",
    "read_file = reader(opened_file)\n",
    "hn = list(read_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The fist five rows of hn are: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['id', 'title', 'url', 'num_points', 'num_comments', 'author', 'created_at'], ['12224879', 'Interactive Dynamic Video', 'http://www.interactivedynamicvideo.com/', '386', '52', 'ne0phyte', '8/4/2016 11:52'], ['10975351', 'How to Use Open Source and Shut the Fuck Up at the Same Time', 'http://hueniverse.com/2016/01/26/how-to-use-open-source-and-shut-the-fuck-up-at-the-same-time/', '39', '10', 'josep2', '1/26/2016 19:30'], ['11964716', \"Florida DJs May Face Felony for April Fools' Water Joke\", 'http://www.thewire.com/entertainment/2013/04/florida-djs-april-fools-water-joke/63798/', '2', '1', 'vezycash', '6/23/2016 22:20'], ['11919867', 'Technology ventures: From Idea to Enterprise', 'https://www.amazon.com/Technology-Ventures-Enterprise-Thomas-Byers/dp/0073523429', '3', '1', 'hswarna', '6/17/2016 0:01']]\n"
     ]
    }
   ],
   "source": [
    "print(hn[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see the first index of the list is the column header. After isolating that into a variable, we have a list of a data set only.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['id', 'title', 'url', 'num_points', 'num_comments', 'author', 'created_at']\n",
      "[['12224879', 'Interactive Dynamic Video', 'http://www.interactivedynamicvideo.com/', '386', '52', 'ne0phyte', '8/4/2016 11:52'], ['10975351', 'How to Use Open Source and Shut the Fuck Up at the Same Time', 'http://hueniverse.com/2016/01/26/how-to-use-open-source-and-shut-the-fuck-up-at-the-same-time/', '39', '10', 'josep2', '1/26/2016 19:30'], ['11964716', \"Florida DJs May Face Felony for April Fools' Water Joke\", 'http://www.thewire.com/entertainment/2013/04/florida-djs-april-fools-water-joke/63798/', '2', '1', 'vezycash', '6/23/2016 22:20'], ['11919867', 'Technology ventures: From Idea to Enterprise', 'https://www.amazon.com/Technology-Ventures-Enterprise-Thomas-Byers/dp/0073523429', '3', '1', 'hswarna', '6/17/2016 0:01'], ['10301696', 'Note by Note: The Making of Steinway L1037 (2007)', 'http://www.nytimes.com/2007/11/07/movies/07stein.html?_r=0', '8', '2', 'walterbell', '9/30/2015 4:12']]\n"
     ]
    }
   ],
   "source": [
    "headers = hn[0]\n",
    "hn = hn[1:]\n",
    "\n",
    "print(headers)\n",
    "print(hn[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we are only concerned with post titles beginning with ```Ask HN``` or ```Show HN```, we will create new list of lists containing just the data for those titles. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "ask_posts = []\n",
    "show_posts = []\n",
    "other_posts = []\n",
    "\n",
    "for row in hn:\n",
    "    title = row[1].lower()\n",
    "    if title.startswith('ask hn'):\n",
    "        ask_posts.append(row)\n",
    "    elif title.startswith('show hn'):\n",
    "        show_posts.append(row)\n",
    "    else:\n",
    "        other_posts.append(row)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we will determine if ask posts or show posts received more comments on average."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_ask_comments = 0\n",
    "total_show_comments = 0\n",
    "\n",
    "\n",
    "for post in ask_posts:\n",
    "    comments = post[4]\n",
    "    comments = int(comments)\n",
    "    total_ask_comments += comments\n",
    "    \n",
    "for post in show_posts:\n",
    "    comments = post[4]\n",
    "    comments = int(comments)\n",
    "    total_show_comments += comments\n",
    "    \n",
    "avg_ask_comments = total_ask_comments / len(ask_posts)    \n",
    "avg_show_comments = total_show_comments / len(show_posts)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on the analysis above, we found out that ask posts receive 14 comments on average and show posts receive 10 comments on average. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will now determine if ask posts created at a *certain time* are more likely to attract comments. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import datetime as dt\n",
    "\n",
    "result_list = []\n",
    "counts_by_hour = {}\n",
    "comments_by_hour = {}\n",
    "\n",
    "for post in ask_posts:\n",
    "    created_time = post[6]\n",
    "    comments = post[4]\n",
    "    comments = int(comments)\n",
    "    result_list.append([created_time,comments])\n",
    "    \n",
    " \n",
    "for result in result_list:\n",
    "    time = result[0]\n",
    "    comment = result[1]\n",
    "    time_dt = dt.datetime.strptime(time, \"%m/%d/%Y %H:%M\")\n",
    "    hour = time_dt.strftime(\"%H\")\n",
    "    if hour not in counts_by_hour:\n",
    "        counts_by_hour[hour] = 1\n",
    "        comments_by_hour[hour] = comment\n",
    "    elif hour in counts_by_hour:\n",
    "        counts_by_hour[hour] += 1\n",
    "        comments_by_hour[hour] += comment\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Above, we created two dictionaries:\n",
    "\n",
    "    - counts_by_hour: contains the number of ask posts created during each hour of the day.\n",
    "    - comments_by_hour: contains the corresponding number of comments ask posts created at each hour received\n",
    "\n",
    "We will use these two dictionaries to calculate the average number of comments for posts created during each hour of the day. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_by_hour= []\n",
    "\n",
    "for hour in comments_by_hour:\n",
    "    avg_by_hour.append([hour, round(comments_by_hour[hour]/counts_by_hour[hour],1)])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Above, we created a list of an hour and the average number of comments for posts created during each hour of the day. \n",
    "\n",
    "In order to identify the hours with the highest number of comments, we are going to sort the list of lists and print the five highest values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[5.6, '09'], [14.7, '13'], [13.4, '10'], [13.2, '14'], [16.8, '16'], [8.0, '23'], [9.4, '12'], [11.5, '17'], [38.6, '15'], [16.0, '21'], [21.5, '20'], [23.8, '02'], [13.2, '18'], [7.8, '03'], [10.1, '05'], [10.8, '19'], [11.4, '01'], [6.7, '22'], [10.2, '08'], [7.2, '04'], [8.1, '00'], [9.0, '06'], [7.9, '07'], [11.1, '11']]\n"
     ]
    }
   ],
   "source": [
    "swap_avg_by_hour = []\n",
    "\n",
    "for row in avg_by_hour:\n",
    "    swap_avg_by_hour.append([row[1], row[0]])\n",
    "\n",
    "print(swap_avg_by_hour)                     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 5 Hours for Ask Posts Comments\n",
      "15:00: 38.6 average comments per post\n",
      "02:00: 23.8 average comments per post\n",
      "20:00: 21.5 average comments per post\n",
      "16:00: 16.8 average comments per post\n",
      "21:00: 16.0 average comments per post\n"
     ]
    }
   ],
   "source": [
    "sorted_swap = sorted(swap_avg_by_hour, reverse=True)\n",
    "\n",
    "print(\"Top 5 Hours for Ask Posts Comments\")\n",
    "\n",
    "for row in sorted_swap[:5]:\n",
    "    comments = row[0]\n",
    "    hour = dt.datetime.strptime(row[1], \"%H\")\n",
    "    hour = hour.strftime(\"%H:%M\")\n",
    "    \n",
    "    print(\"{hour}: {comments} average comments per post\".format(hour = hour, comments = comments))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
